{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - Find the perfect place to stay in Texas!\n",
    "\n",
    "###### Alessandro Flaborea, Egon Ferri, Melis Kaymaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The homework consists in analyzing the text of Airbnb property listings and building a search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag, ne_chunk\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a `.tsv` file for each record of the dataset.\n",
    "First thing to do is reading the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv(r'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\Airbnb_Texas_Rentals.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create `.tsv` files and store them in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-24b6b679005a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\doc\\doc_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s\\t'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[0mremembers\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstate\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mcalls\u001b[0m \u001b[0mto\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m    187\u001b[0m         \u001b[0mCreates\u001b[0m \u001b[0man\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(f.index.max()+1):\n",
    "    op = open(r'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\doc\\doc_' + str(i) + '.tsv', 'w', encoding=\"utf-8\")\n",
    "    for j in range(10):\n",
    "        op.write('%s\\t' %f.iloc[i, j])\n",
    "    op.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to create two different Search Engines that, given as input a query, return the houses that match the query.\n",
    "\n",
    "As a first common step, we want to preprocess the documents by\n",
    "\n",
    "1. Removing stopwords\n",
    "2. Removing punctuation\n",
    "3. Stemming\n",
    "\n",
    "Then we want to build a file named `vocabulary.txt`, that maps each word to an integer (`term_id`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS\n",
    "def preprocess(l):\n",
    "    final = []\n",
    "    for i in l:\n",
    "        if not((ps.stem(i) in stopWords) or (ps.stem(i) in (string.punctuation) )):\n",
    "            final.append(ps.stem(i))\n",
    "    return (final)\n",
    "\n",
    "def vocabularization(vocabulary, final, index):\n",
    "    for word in final:\n",
    "        if not(word in vocabulary):\n",
    "            vocabulary[word] = index\n",
    "            index = index + 1\n",
    "    return(vocabulary, index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "string.punctuation = string.punctuation + '–“”’'\n",
    "\n",
    "vocabulary= {}\n",
    "index = 0\n",
    "\n",
    "for i in range(18259):\n",
    "    \n",
    "    op = open(r'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\doc\\doc_' + str(i) + '.tsv', 'r', encoding=\"utf-8\")\n",
    "    for line in op:\n",
    "        ou = line.strip().split('\\t')\n",
    "        sentence = ou[5].replace('\\\\n', ' ').replace('/', ' ').replace('*', ' ').replace('\\\\r', ' ').replace('\\\\t', ' ') + ' ' + ou[8].replace('\\\\n', ' ').replace('/', ' ').replace('*', ' ').replace('\\\\r', ' ').replace('\\\\t', ' ')\n",
    "    op.close()\n",
    "        \n",
    "    #preprocessing data deleting stop words, punctuations, ecc.  \n",
    "    final = preprocess(word_tokenize(sentence))\n",
    "    \n",
    "    # IF  word not in vocabulary -> add the word\n",
    "    vocabulary, index = vocabularization(vocabulary, final, index)\n",
    "            \n",
    "op = open(r'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\vocabulary.txt', 'w', encoding=\"utf-8\")\n",
    "op.write(str(vocabulary))\n",
    "op.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Conjunctive query\n",
    "At this moment, we narrow out interest on the `description` and `title` of each document. It means that the first Search Engine will evaluate queries with respect to the aforementioned information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1) Creating our index!\n",
    "\n",
    "We want to create the Inverted Index. It will be a dictionary of this format:\n",
    "\n",
    "```\n",
    "{\n",
    "term_id_1:[document_1, document_2, document_4],\n",
    "term_id_2:[document_1, document_3, document_5, document_6],\n",
    "...}\n",
    "```\n",
    "\n",
    "where _document\\_i_ is the *id* of a document that contains the word.\n",
    "\n",
    "We also want to store it in a separate file and load it in memory when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "\n",
    "for file in range(18259):\n",
    "\n",
    "    op = open(r'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\doc\\doc_' + str(file) + '.tsv', 'r', encoding=\"utf-8\")\n",
    "    for line in op:\n",
    "        ou = line.strip().split('\\t')\n",
    "        sentence = ou[5].replace('\\\\n', ' ').replace('/', ' ').replace('*', ' ').replace('\\\\r', ' ').replace('\\\\t', ' ') + ' ' + ou[8].replace('\\\\n', ' ').replace('/', ' ').replace('*', ' ').replace('\\\\r', ' ').replace('\\\\t', ' ')\n",
    "    op.close()\n",
    " \n",
    "    \n",
    "    #preprocessing data deleting stop words, punctuations, ecc.  \n",
    "    final = preprocess(word_tokenize(sentence))\n",
    "    \n",
    "    \n",
    "    #CREATING INVERTED INDEX\n",
    "    for word in final:\n",
    "        index = vocabulary[word]\n",
    "        if not (index in inverted_index):\n",
    "            inverted_index[index] = ['doc_' + str(file)]\n",
    "        elif not('doc_' + str(file) in inverted_index[index]):\n",
    "            inverted_index[index] = inverted_index[index] + ['doc_' + str(file)]\n",
    "\n",
    "op = open(r'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\inverted_index.txt', 'w', encoding=\"utf-8\")\n",
    "op.write(str(inverted_index))\n",
    "op.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2) Execute the query\n",
    "Now given a query, that we let the user enter:\n",
    "```\n",
    "queen netflix\n",
    "```\n",
    "we want that the Search Engine returns a list of documents that contains all the words in the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netflix bed Bienvenidos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['netflix', 'bed', 'bienvenido']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = input()\n",
    "\n",
    "#names, l = chunking(sentence) \n",
    "    \n",
    "#preprocessing data deleting stop words, punctuations, ecc.  \n",
    "final = preprocess(word_tokenize(user_query))\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traducing the query in our 'language':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = {}\n",
    "inverted_idx = {}\n",
    "i=0\n",
    "for word in final: \n",
    "    voc[i]  = vocabulary[word]\n",
    "    i = i+1\n",
    "for index in range(i):\n",
    "    inverted_idx[voc[index]] = inverted_index[voc[index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding list of docs that contain all the words in the query and printing them in the format that we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >title</th> \n",
       "        <th class=\"col_heading level0 col1\" >description</th> \n",
       "        <th class=\"col_heading level0 col2\" >city</th> \n",
       "        <th class=\"col_heading level0 col3\" >url</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8level0_row0\" class=\"row_heading level0 row0\" >57</th> \n",
       "        <td id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8row0_col0\" class=\"data row0 col0\" >Lovely Katy Home (3BR/2B) - Fantastic Location</td> \n",
       "        <td id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8row0_col1\" class=\"data row0 col1\" >Bienvenidos! This gorgeous one-story home offers 3 bedrooms, 2 bathrooms and a 2-car garage. The elegant plan features a study room equipped with a sofa bed, gorgeous kitchen and great living space with TV (netflix included). It is tailored for all. We are located in Katy, TX, in close proximity to Katy Mills Shopping Mall, Houston Premium Outlets, Typhoon Water Park, energy corridor, and new hospital area. We sincerely hope you will have a wonderful and profitable stay in our dear town of Katy.</td> \n",
       "        <td id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8row0_col2\" class=\"data row0 col2\" >Katy</td> \n",
       "        <td id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8row0_col3\" class=\"data row0 col3\" >https://www.airbnb.com/rooms/19387030?location=Cinco%20Ranch%2C%20TX</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8level0_row1\" class=\"row_heading level0 row1\" >12924</th> \n",
       "        <td id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8row1_col0\" class=\"data row1 col0\" >Lovely Katy Home (3BR/2B) - Fantastic Location</td> \n",
       "        <td id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8row1_col1\" class=\"data row1 col1\" >Bienvenidos! This gorgeous one-story home offers 3 bedrooms, 2 bathrooms and a 2-car garage. The elegant plan features a study room equipped with a sofa bed, gorgeous kitchen and great living space with TV (netflix included). It is tailored for all. We are located in Katy, TX, in close proximity to Katy Mills Shopping Mall, Houston Premium Outlets, Typhoon Water Park, energy corridor, and new hospital area. We sincerely hope you will have a wonderful and profitable stay in our dear town of Katy.</td> \n",
       "        <td id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8row1_col2\" class=\"data row1 col2\" >Katy</td> \n",
       "        <td id=\"T_c5c3b5c2_e8d2_11e8_a2b5_204747782cb8row1_col3\" class=\"data row1 col3\" >https://www.airbnb.com/rooms/19387030?location=Beasley%2C%20TX</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28337e97400>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding list of docs that contain all the words in the query\n",
    "docs = []\n",
    "\n",
    "for i in range(18259):\n",
    "    doc = 'doc_' + str(i)\n",
    "    b = True\n",
    "    for j in voc.values(): \n",
    "        b = b and (doc in inverted_idx[j])\n",
    "    if b:\n",
    "        docs.append(i)\n",
    "\n",
    "df = f.filter(items = ['title', 'description', 'city', 'url']).loc[docs]\n",
    "df.description = list(map(lambda x: x.replace('\\\\n', ' '), df.description.tolist()))\n",
    "df.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Conjunctive query & Ranking score\n",
    "In the new Search Engine, given a query, we want to get the *top-k* (the choice of *k* it's up to you!) documents related to the query. In particular we want:\n",
    "\n",
    "* Find all the documents that contains all the words in the query (as before...).\n",
    "* Sort them by their similarity with the query\n",
    "* Return in output *k* documents, or all the documents with non-zero similarity with the query when the results are less than _k_.\n",
    "\n",
    "To solve this task, we use the *tfIdf* score, and the _Cosine similarity_. Let's see how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing; we create a new inverted index that contains `tfIdf`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index_2 = {}\n",
    "\n",
    "for file in range(18259):\n",
    "\n",
    "    op = open(r'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\doc\\doc_' + str(file) + '.tsv', 'r', encoding=\"utf-8\")\n",
    "    for line in op:\n",
    "        ou = line.strip().split('\\t')\n",
    "        sentence = ou[5].replace('\\\\n', ' ').replace('/', ' ').replace('*', ' ').replace('\\\\r', ' ').replace('\\\\t', ' ') + ' ' + ou[8].replace('\\\\n', ' ').replace('/', ' ').replace('*', ' ').replace('\\\\r', ' ').replace('\\\\t', ' ')\n",
    "    op.close()\n",
    " \n",
    "    \n",
    "    #preprocessing data deleting stop words, punctuations, ecc.  \n",
    "    final = preprocess(word_tokenize(sentence))\n",
    "    \n",
    "    \n",
    "    #CREATING INVERTED INDEX\n",
    "    for word in final:\n",
    "        index = vocabulary[word]\n",
    "        \n",
    "        tf = final.count(word) / len(final)\n",
    "        idf = math.log( 18259 / len(inverted_index[vocabulary[word]]))\n",
    "        \n",
    "        if not (index in inverted_index_2):\n",
    "            inverted_index_2[index] = [('doc_' + str(file), tf*idf )]\n",
    "        elif not(('doc_' + str(file), tf*idf)  in inverted_index_2[index]):\n",
    "            inverted_index_2[index] = inverted_index_2[index] + [('doc_' + str(file), tf*idf)]\n",
    "\n",
    "\n",
    "op = open(r'C:\\Users\\mccol\\Desktop\\Sapienza\\ADM\\HW3\\inverted_index_2.txt', 'w', encoding=\"utf-8\")\n",
    "op.write(str(inverted_index_2))\n",
    "op.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netflix bed Bienvenidos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['netflix', 'bed', 'bienvenido']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = input()\n",
    "\n",
    "#preprocessing data deleting stop words, punctuations, ecc.  \n",
    "final_query = preprocess(word_tokenize(user_query))\n",
    "final_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traducing the query in our 'language':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = {}\n",
    "inverted_query = {}\n",
    "i=0\n",
    "for word in final_query: \n",
    "    voc[i]  = vocabulary[word]\n",
    "    i = i+1\n",
    "for index in range(i):\n",
    "    inverted_query[voc[index]] = inverted_index_2[voc[index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding nominator of cosine similarity formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = {}\n",
    "index = 0\n",
    "for i in inverted_query:\n",
    "    for j in inverted_query[i]:\n",
    "        if index == 0:\n",
    "            n[j[0]] = [j[1]]\n",
    "        elif (not (j[0] in n)):\n",
    "            n[j[0]] = [0]*index + ([j[1]])\n",
    "        else:   \n",
    "            n[j[0]] = n[j[0]] + [0]*(index - len(n[j[0]])) + ([j[1]])\n",
    "    index = index + 1\n",
    "\n",
    "for i in n:\n",
    "    if len(n[i]) < len(final_query) :\n",
    "        n[i] = n[i] + [0]*(len(final_query)-len(n[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding tfidfs of the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4185284421457318, 0.4563606817729836, 2.538396270266838]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_query = []  \n",
    "for word in final_query:\n",
    "    tf_query = final_query.count(word) / len(final_query)\n",
    "    idf_query = math.log( 18259 / len(inverted_index[vocabulary[word]]))\n",
    "    tfidf_query.append(tf_query * idf_query)\n",
    "tfidf_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding denominator of our dear formula: norm of the query and norm of docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "norm_query = numpy.sqrt(sum(list(map(lambda x: x**2, tfidf_query))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_doc = {}\n",
    "for i in range(18259):\n",
    "    doc = 'doc_'+ str(i)\n",
    "    nomin = 0\n",
    "    for i in inverted_query:\n",
    "        for j in inverted_query[i]:\n",
    "            if j[0] == doc :\n",
    "                nomin = nomin + j[1]**2\n",
    "                norm_doc[doc] = nomin\n",
    "for i in norm_doc:\n",
    "    norm_doc[i] = numpy.sqrt(norm_doc[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorting them with haep algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "daje= []\n",
    "for i in n:\n",
    "    st = i\n",
    "    cos = numpy.dot(tfidf_query, n[st])\n",
    "    cosine = round(cos / (norm_doc[st]*norm_query), 10)\n",
    "    #the other formula:\n",
    "    #import scipy\n",
    "    #cosine = 1 - scipy.spatial.distance.cosine(tfidf_query, n[st])\n",
    "    daje.append((cosine, i ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq_max\n",
    "heap_max = []\n",
    "for i in daje:\n",
    "    heapq_max.heappush_max(heap_max, i)\n",
    "heap_max\n",
    "\n",
    "best_cosine = []\n",
    "docs = []\n",
    "for i in range(5):\n",
    "    cos = heapq_max.heappop_max(heap_max)\n",
    "    best_cosine.append(cos[0])\n",
    "    docs.append(int(cos[1][4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"col_heading level0 col0\" >title</th> \n",
       "        <th class=\"col_heading level0 col1\" >description</th> \n",
       "        <th class=\"col_heading level0 col2\" >city</th> \n",
       "        <th class=\"col_heading level0 col3\" >url</th> \n",
       "        <th class=\"col_heading level0 col4\" >ranking</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row0_col0\" class=\"data row0 col0\" >Lovely Katy Home (3BR/2B) - Fantastic Location</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row0_col1\" class=\"data row0 col1\" >Bienvenidos! This gorgeous one-story home offers 3 bedrooms, 2 bathrooms and a 2-car garage. The elegant plan features a study room equipped with a sofa bed, gorgeous kitchen and great living space with TV (netflix included). It is tailored for all. We are located in Katy, TX, in close proximity to Katy Mills Shopping Mall, Houston Premium Outlets, Typhoon Water Park, energy corridor, and new hospital area. We sincerely hope you will have a wonderful and profitable stay in our dear town of Katy.</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row0_col2\" class=\"data row0 col2\" >Katy</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row0_col3\" class=\"data row0 col3\" >https://www.airbnb.com/rooms/19387030?location=Cinco%20Ranch%2C%20TX</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row0_col4\" class=\"data row0 col4\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row1_col0\" class=\"data row1 col0\" >Lovely Katy Home (3BR/2B) - Fantastic Location</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row1_col1\" class=\"data row1 col1\" >Bienvenidos! This gorgeous one-story home offers 3 bedrooms, 2 bathrooms and a 2-car garage. The elegant plan features a study room equipped with a sofa bed, gorgeous kitchen and great living space with TV (netflix included). It is tailored for all. We are located in Katy, TX, in close proximity to Katy Mills Shopping Mall, Houston Premium Outlets, Typhoon Water Park, energy corridor, and new hospital area. We sincerely hope you will have a wonderful and profitable stay in our dear town of Katy.</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row1_col2\" class=\"data row1 col2\" >Katy</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row1_col3\" class=\"data row1 col3\" >https://www.airbnb.com/rooms/19387030?location=Beasley%2C%20TX</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row1_col4\" class=\"data row1 col4\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row2_col0\" class=\"data row2 col0\" >Bienvenidos 2 - upstairs Cal-king</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row2_col1\" class=\"data row2 col1\" >Located in a gated community, the room is a small guest bedroom on the second floor, a full bath is located right by the bedroom, the bathroom is considered a shared bath. Our home is close to HWY 151 making moving around the city easy on highways. Listed rate includes city and county taxes. FYI Airbnb assess state taxes on top of listed price.</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row2_col2\" class=\"data row2 col2\" >San Antonio</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row2_col3\" class=\"data row2 col3\" >https://www.airbnb.com/rooms/8607610?location=Castroville%2C%20TX</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row2_col4\" class=\"data row2 col4\" >0.862386</td> \n",
       "    </tr>    <tr> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row3_col0\" class=\"data row3 col0\" >Mi casa es su Casa. Travel instyle.</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row3_col1\" class=\"data row3 col1\" >Gorgeous 3 master suites w/ privatel baths, all with designer vanities. Hardwood floors, chefs kitchen, 2000 square ft located in N. Dallas. Cozy backyard.Private parking, beautifully maintained neighborhood, pool and tennis courts. Just seconds off of 635 and 75. If you are a traveler who loves to stay/relax in style- this is it. Bienvenidos  My wife works every 3rd day and is out for 24hrs. She is a police officer. I am on a mini break from work but I have invested in a business. I am usually out of the home meeting with clients. We do have a baby dog that is hypoallergenic. Sebastian is a Miniature Schnauzer who is very sweet, house trained, and VERY quiet. He has not been allowed in the extra bedrooms.   The neighborhood is filled with 25+ something year olds that are yound professionals. It is very quiet. In this community- we have access to 2 large swimming pools/hot tubs, tennis courts, and a fenced in dog park.  There are many bus routes that are within walking distance as well as the Dart Rail.  If you are a traveler who loves to travel in style but may be on a budget... This has your name written all over it. We provide: clean linen/ towels, traveler kits (so in case you forgot your toothbrush we have various colors to choose from) directions, and coffee in the morning.  We accommodate late check outs as well.   EXTRAS EXTRAS EXTRAS AVAILABLE!!!! 1. If you want personal groceries waiting for you upon check in and only for your personal enjoyment. You can send me a detailed email and I will provide this feature for the cost of goods (receipt will be provided) plus a 35% fee.  The grocery stores offered are: Whole Foods, Trader Joe's, Spec's Wine, Spirits and Finer Foods, Albertson's (Kosher is available here), and Kroger.  All guest's have full access to a chef inspired modern kitchen, living/lounge area with a big screen TV/with cable, an upstairs private balcony, state of the art laundry room, and a private backyard with an extra large stainless steel grill.  I am here to help and help you get settled into your bedroom :) I am reachable via text/call/email. I am usually home in the evenings.  We have free street parking, lovely tennis courts, and a very well mainteneced community pool. Our home is minutes away from 2 major highways and public transportation is meters away from our front door step.  There are many DART bus stops that are literally a 1 minute walk that can take you to the DART rail. Be sure to use their website to help figure out your commute etc. You can use Richland College as a starting point.  If your stay is a week or longer then you are much more like a temporary roommate, in which, you are responsible for your own toiletries, laundry detergents, and are responsible in the upkeep of your bedroom/bath. I have renovated and designed the townhome from the ground up. I take pride in what I have created and feel guest's should take pride in their rooms/the home itself. That is why you have chosen to stay with us :D</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row3_col2\" class=\"data row3 col2\" >Dallas</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row3_col3\" class=\"data row3 col3\" >https://www.airbnb.com/rooms/790791?location=Addison%2C%20TX</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row3_col4\" class=\"data row3 col4\" >0.862386</td> \n",
       "    </tr>    <tr> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row4_col0\" class=\"data row4 col0\" >Freshly remodeled midtown bungalow - close to all!</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row4_col1\" class=\"data row4 col1\" >Bienvenidos to our 1916 bungalow! We have taken special care to keep this craftsman work of art as original as possible while adding moderate modern convenience &amp; style. Set amongst the quiet yet central and walkable Alta Vista neighborhood in midtown San Antonio we know you will enjoy a refreshing cool down after a day exploring all of the local attractions - Zoo, San Pedro Park, Breckenridge Golf Course, the Japanese Tea Garden, Hildebrand St. Antiques, the Pearl, &amp; of course, the Riverwalk!</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row4_col2\" class=\"data row4 col2\" >San Antonio</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row4_col3\" class=\"data row4 col3\" >https://www.airbnb.com/rooms/18943624?location=Alamo%20Heights%2C%20TX</td> \n",
       "        <td id=\"T_711acf68_e8d4_11e8_84ed_204747782cb8row4_col4\" class=\"data row4 col4\" >0.862386</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28337fa64e0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = f.filter(items = ['title', 'description', 'city', 'url']).loc[docs]\n",
    "df.description = list(map(lambda x: x.replace('\\\\n', ' '), df.description.tolist()))\n",
    "df['ranking'] = best_cosine\n",
    "df.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
